from fastapi import FastAPI
from pydantic import BaseModel
from typing import Optional, List, Dict, Any, Tuple 
from datetime import datetime
import os
from fastapi.responses import StreamingResponse, FileResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from app.llm_service import llm_service
import logging
import traceback
import asyncio
from app.config import ConfigManager
from app.db.factory import DatabaseFactory
from app.schema_loader import load_schema
import time

# Import both regex-based and the conceptual LLM-based functions
from app.nl_to_sql import generate_sql_via_llm

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI()

# Serve static files for the frontend
app.mount("/static", StaticFiles(directory="public"), name="static")

# Global config manager
config_manager = ConfigManager()
DEFAULT_DB_NAME = config_manager.get_active_database()

def get_db_adapter(db_name: str = 'default'):
    db_config = config_manager.get_database_config(db_name)
    if not db_config:
        raise ValueError(f"No database config found for '{db_name}'")
    db = DatabaseFactory.create_database(db_config)
    db.connect()
    return db

class ChatMessage(BaseModel):
    role: str # "user" or "assistant"
    content: str

class QueryRequest(BaseModel):
    question: str
    chat_history: Optional[List[ChatMessage]] = None
    # start_timestamp and end_timestamp are not directly used here anymore
    # as they should be part of the natural language question if needed.

class QueryResponse(BaseModel):
    answer: Optional[str] = None
    query: Optional[str] = None
    results: Optional[List[Dict[str, Any]]] = None
    error: Optional[str] = None
    debug_info: Optional[str] = None # For LLM prompts or other info

def format_results_for_display(results: List[Tuple], column_names: List[str]) -> str:
    """Formats SQL results into a human-readable string."""
    if not results:
        return "No data found for your query."

    # If a single value is returned (e.g., SUM, COUNT)
    if len(results) == 1 and len(results[0]) == 1:
        return str(results[0][0])

    # For multiple rows/columns, create a simple table string
    header = " | ".join(column_names)
    rows_str = [" | ".join(map(str, row)) for row in results]
    return "\n".join([header] + rows_str)

@app.get("/")
async def read_index():
    return FileResponse('public/index.html')

@app.get("/speech-test")
async def speech_test_page():
    """Serve the speech recognition test page"""
    return FileResponse('public/speech_test.html')

@app.post('/ask', response_model=QueryResponse)
async def ask_question(req: QueryRequest, db_name: str = DEFAULT_DB_NAME):
    sql_query = None
    debug_message = ""
    db = None
    timings = {}
    total_start = time.time()

    debug_message = ""
    chat_history_dicts = [msg.dict() for msg in req.chat_history] if req.chat_history else None
    # Dynamically load schema for the selected db_name
    try:
        schema = load_schema(db_name=db_name)
    except Exception as e:
        debug_message = f"Schema load error: {e}"
        return QueryResponse(error=f"Schema load error: {e}", debug_info=debug_message)
    llm_start = time.time()
    sql_query_llm = generate_sql_via_llm(req.question, chat_history_dicts, db_schema=schema, db_name=db_name)
    timings['llm'] = time.time() - llm_start
    if sql_query_llm:
        if "<dynamic_start_time>" in sql_query_llm:
            debug_message += " LLM produced a template. Dynamic timestamp replacement is conceptual."
            return QueryResponse(error="LLM generated a query template that requires dynamic data not yet implemented.", query=sql_query_llm, debug_info=debug_message)
        sql_query = sql_query_llm
        debug_message += f" Query generated by LLM: {sql_query}"
    else:
        debug_message += " LLM also failed to generate a query."

    if not sql_query:
        return QueryResponse(error="Sorry, I couldn't understand your question or convert it to a database query.", debug_info=debug_message)

    try:
        db = get_db_adapter(db_name)
        mysql_start = time.time()
        results, column_names = db.execute_query(sql_query)
        timings['mysql'] = time.time() - mysql_start
        formatted_answer = format_results_for_display(results, column_names)
        results_as_dict = [dict(zip(column_names, row)) for row in results]
        timings['total'] = time.time() - total_start
        logger.info(f"[TIMING] LLM: {timings['llm']:.2f}s, MySQL: {timings['mysql']:.2f}s, Total: {timings['total']:.2f}s for question: {req.question}")
        return QueryResponse(answer=formatted_answer, query=sql_query, results=results_as_dict, debug_info=debug_message)
    except Exception as e:
        timings['total'] = time.time() - total_start
        logger.error(f"[TIMING] LLM: {timings.get('llm', 0):.2f}s, MySQL: {timings.get('mysql', 0):.2f}s, Total: {timings['total']:.2f}s for question: {req.question}")
        return QueryResponse(error=f"Database error: {e}", query=sql_query, debug_info=debug_message)
    finally:
        if db:
            db.disconnect()

@app.post('/ask/stream') 
async def ask_question_stream(req: QueryRequest, db_name: str = DEFAULT_DB_NAME):
    """Streaming version of the ask endpoint."""
    async def generate_stream():
        db = None
        try:
            chat_history_dicts = [msg.dict() for msg in req.chat_history] if req.chat_history else None
            # Dynamically load schema for the selected db_name
            try:
                schema = load_schema(db_name=db_name)
            except Exception as e:
                yield f"Schema load error: {e}\n"
                return
            sql_query = generate_sql_via_llm(req.question, chat_history_dicts, db_schema=schema, db_name=db_name)
            if not sql_query:
                yield "Error: Could not generate SQL query.\n"
                return
            db = get_db_adapter(db_name)
            results, column_names = db.execute_query(sql_query)
            yield "SQL Query:\n"
            yield f"{sql_query}\n\n"
            yield "Results:\n"
            if column_names:
                yield " | ".join(column_names) + "\n"
                yield "-" * (sum(len(col) + 3 for col in column_names) -1) + "\n" 
            for row in results:
                yield " | ".join(str(cell) for cell in row) + "\n"
        except Exception as e:
            yield f"Error: {str(e)}\n"
        finally:
            if db:
                db.disconnect()
    return StreamingResponse(generate_stream(), media_type="text/plain")

# To run: uvicorn app.chat_service:app --reload 